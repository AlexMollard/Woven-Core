---
title: My Learning Plan
description: How I'm breaking down modern Vulkan learning into stages.
---

## My Approach

I've already done Vulkan 1.3 with dynamic rendering and bindless. WovenCore is about **expanding into Vulkan 1.4** and features I haven't fully used before.

**What I already know:**
- Dynamic rendering (used in previous renderer)
- Bindless descriptors (implemented before)
- Synchronization2 (already comfortable with)
- Basic resource management patterns

**What I'm expanding:**
- Shader objects (never used in previous engine - always stuck with pipelines)
- Mesh shaders (experimented but never made them primary path)
- Vulkan 1.4 features and modern baseline
- GPU-driven workflows at scale
- Timeline semaphores (would use but driver crashes)

## Stage 1: Setup (Already Comfortable)

**Goal:** Vulkan 1.4 context setup. I've done this before in 1.3, now with updated feature requirements.

### Instance, Physical Device, Logical Device

**What I already know:** Basic flow is the same as 1.3. Instance, pick GPU, create logical device.

**What's different in 1.4:** Using vk-bootstrap but requiring Vulkan 1.4 feature baseline. Shader objects, mesh shaders as required (not optional).

**My approach:** `SelectPhysicalDevice` in GraphicsSystem enforces modern features. No fallback paths - if hardware doesn't support it, I don't run.

### Surface and Swapchain

**Already comfortable with this.** Using SDL3 (new to me) instead of glfw, but swapchain creation is identical to my 1.3 renderer.

**My pattern:** Query formats/present modes, pick best available. MAILBOX for low latency if available, FIFO as fallback.

### Command Buffers and Submission

**Already know:** Per-frame command pools for multi-frame-in-flight. Did this in previous renderer.

**My pattern:**
- `BeginFrame`: Reset pool, begin command buffer  
- Record rendering commands
- `EndFrame`: Submit with semaphores

**No changes here** - this pattern works and I understand it.

## Stage 2: New Features (What I'm Actually Learning)

**Goal:** Use features I haven't done before or only experimented with. This is the real learning.

### Dynamic Rendering (Already Done)

**My experience:** Used in previous 1.3 renderer. Comfortable with `vkCmdBeginRendering` and inline attachments.

**What I'm refining:** Making sure I understand performance characteristics. When dynamic rendering causes extra work vs being optimal.

**Current usage:** Standard pattern - color + depth attachments set up inline in `RecordFrame`. Nothing new here.

### Shader Objects (NEW - Never Used in Previous Engine)

**My experience:** Always stuck with pipelines before. Experimented with shader objects but never committed.

**Why I'm doing this now:** No pipeline explosion. State is explicit in command buffer. Want to understand if the flexibility is worth the validation overhead.

**What I'm learning:** Every piece of state becomes a `vkCmdSet*` call. Look at `SetDynamicState` in GraphicsSystem - it's a lot of calls per frame. Is this actually better than pipelines? That's what I want to understand.

**Trade-off I'm exploring:** More CPU-side state setting vs no pre-baking. Does driver optimize this well enough? Need to profile.

### Mesh Shaders (Expanding - Experimented Before)

**My experience:** Played with mesh shaders in previous project but never made them the primary path. Always fell back to vertex shaders.

**Why I'm doing this now:** Want to commit to mesh shader workflow. GPU-driven culling, LOD, procedural geometry. This is the future.

**What I'm learning:** Not just the API (I know that), but the PATTERNS. When mesh shaders are worth it. How to structure workgroup dispatch for real culling, not toy examples.

**Current state:** Just a triangle to verify API. Next step: real mesh culling and LOD selection on GPU.

**Critical lesson:** Mesh shaders are a different mental model. I need to think in workgroups and meshlets, not vertices.

## Stage 3: Resources and Memory (Refining)

**Goal:** I've done this before. Now it's about refining patterns and deeper understanding.

### VMA (Vulkan Memory Allocator)

**My experience:** Used in previous renderer. Comfortable with `vmaCreateImage` and `vmaCreateBuffer`.

**What I'm refining:** Nothing new here. VMA just works. Same pattern as before.

### Bindless Descriptors (Already Done)

**My experience:** Implemented in previous 1.3 renderer. Already comfortable with `runtimeDescriptorArray`, `updateAfterBind`, `partiallyBound` flags.

**What I'm expanding:** Previously did bindless, but smaller scale. This time: 16K texture slots, planning for GPU-driven material selection.

**Current implementation:** Read `CreateBindlessDescriptors` in GraphicsSystem. Same pattern as before, just bigger scale.

**What I'm learning:** Not the API (I know that), but best practices at scale. How to manage 16K slots efficiently. When to update descriptors. Update frequency patterns.

### Image Layouts and Barriers (Already Done)

**My experience:** Used synchronization2 barriers in previous 1.3 renderer. Understand layouts, access patterns, pipeline stages.

**Current pattern:** `TransitionImage` uses VkImageMemoryBarrier2. Manual layout tracking to avoid invalid transitions.

**What I'm refining:** Not the API (I know it), but deeper understanding of performance cost. Which barriers are expensive? When can I batch them? What's the overhead?

**Past lesson:** Tried VK_IMAGE_LAYOUT_GENERAL for everything. Validation warned about performance. Learned to use optimal layouts.

**Future consideration:** Render graphs could automate this. For now, manual tracking keeps me aware of what's happening.

## Stage 4: Performance and Debugging (Deepening)

**Goal:** I know the basics of profiling and validation. Now it's about deeper insights and optimization patterns.

### Validation Layers

**My experience:** Always run with full validation. Best practices, GPU-assisted, sync validation.

**My approach:** Fix every warning immediately. I've learned validation is almost always right.

**What I'm expanding:** Understanding which validation errors are critical vs informational. Learning performance validation messages.

### Tracy GPU Profiler

**My status:** Tracy integrated. Basic CPU profiling works. GPU zones not added yet.

**What I'm learning:** Where frame time ACTUALLY goes. Not guesses - measurements. Barrier cost. Dispatch cost. Blit cost.

**Next step:** Add `TracyVkZone` around GPU work. See timeline. Find bottlenecks.

**Goal:** Understand if I'm GPU-bound or CPU-bound. Where synchronization points hurt. What the real costs are.

### Frame Pacing and Multi-Frame-In-Flight

**My experience:** Implemented 2-frames-in-flight in previous renderer. Understand fences vs semaphores.

**Current pattern:** Same as before - overlap CPU recording with GPU execution. Works well.

**What I'm refining:** Understanding exact timing. When does CPU stall waiting for GPU? Can I add async compute work?

### Timeline Semaphores (Not Using Yet)

**Why they matter:** Binary semaphores are one-shot. Timeline semaphores have integer values. You can signal value 5, wait for value 3, etc. Perfect for multi-queue work and async uploads.

**My situation:** NOT using them. Caused PC hangs on my hardware (driver issue). Using binary semaphores + fences instead.

**What I learned:** Driver bugs exist. Modern features aren't always stable. Need fallbacks. Binary semaphores work fine for 2-frames-in-flight.

**Future plan:** May try again with driver updates or different GPU. For now, not blocking my learning.
